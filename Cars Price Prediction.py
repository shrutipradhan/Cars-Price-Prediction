# -*- coding: utf-8 -*-
"""AI Coursework.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17CqRGDOgvmP5LTD1YRcaNumWZDQAqZ10

### Dataset Overview

<hr style="border:2px solid black">
"""

# importing libraries essential for the task for further use
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import missingno as msno
from sklearn.preprocessing import LabelEncoder
from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator
from sklearn.model_selection import train_test_split
from sklearn.feature_selection import mutual_info_regression
from sklearn.ensemble import RandomForestRegressor
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.feature_selection import SelectKBest
from sklearn import metrics
from sklearn.metrics import mean_absolute_error
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import cross_val_score, KFold, train_test_split
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
from keras.models import Sequential
from keras.layers import Dense
from sklearn.model_selection import GridSearchCV

# to ignore all the warnings encountered during the functionality
import warnings
warnings.filterwarnings('ignore')

# Commented out IPython magic to ensure Python compatibility.
# to show plot on notebook
# %matplotlib inline

# loading the data
cars_df=pd.read_csv("/content/drive/MyDrive/AI Coursework/cars.csv")

# understanding the structure of the dataset
cars_df.shape

"""###### The dataset consists of 2059 records and 20 features."""

# displaying first 5 records of the dataset
cars_df.head()

# displaying last 5 records of the dataset
cars_df.tail()

# displaying all features of the data set
cars_df.columns

# understanding the features and it's data types
cars_df.info()

"""###### The dataset consists of features of type object, integer as well as float.


###### Observing the "Non-Null Count" column of the output, it can be derived that there are multiple features with null values.

<hr style="border:2px solid black">

### Data Cleaning

<hr style="border:2px solid black">
"""

# to change all the attributes to lowercase
for x in cars_df.columns:
    if type(cars_df.loc[1,x]) is str:
        cars_df[x]=cars_df[x].str.lower()

cars_df.head()

"""###### 1. Looking for null values"""

# visualising using bar chart to see the number of missing values in each feature

msno.bar(cars_df, color='purple')

# to check unwanted characters representing null vales in the dataset
for x in cars_df.columns:
    print(x,':',cars_df[(cars_df[x]=='?') | (cars_df[x]=='') | (cars_df[x]=='-') ][x].count())

# looking for null values
cars_df.isnull().sum()

"""###### 2. Dealing with null values

It is observed that there are missing values in the following features:

Engine, Max Power, Max Torque, Drivetrain, Length, Width, Height, Seating Capacity and Fuel Tank Capacity.
"""

# displaying records with missing values
cars_df[(cars_df['Engine'].isnull()==True) | (cars_df['Max Power'].isnull()==True)  | (cars_df['Max Torque'].isnull()==True)  | (cars_df['Drivetrain'].isnull()==True) | (cars_df['Length'].isnull()==True) | (cars_df['Width'].isnull()==True) | (cars_df['Height'].isnull()==True) | (cars_df['Seating Capacity'].isnull()==True) | (cars_df['Fuel Tank Capacity'].isnull()==True) ]

"""There are total 185 records that have atleast one missing value. 

Observing closely, there are many records with multiple missing values. Hence, considering 3 as the threshold for number of nulls in a record, dropping the records with more than 3 null values.
"""

# dropping records with more than 3 null values
cars_df.dropna(axis=0, how='any', thresh=17, subset=None, inplace=True)

"""Checking for the null values remaining in the data."""

# looking for null values in each feature
cars_df.isnull().sum()

"""Thus, there are only two features left with missing values i.e, Drivetrain and Fuel Tank Capacity.

As Drive train is a categorical feature, mathematical computations will not work.

Hence, understanding the feature to figure out the best way to deal with null values in it.
"""

# analysing the feature Drivetrain
cars_df['Drivetrain'].describe()

"""Thus, there are 3 different categories in Drivetrain and the most popular category in the feature is FWD as 1323 out of 1916 records have the Drivetrain category as FWD.

Hence, it will be safe to replace the null values with the majority class i.e, FWD.
"""

# replacing null values in Drivetrain as FWD
cars_df['Drivetrain'].fillna('fwd',inplace= True)

cars_df.isnull().sum()

"""
As Fuel Tank Capacity is a numerical feature, the most commonly used meathod is replacing with the mean of the category. However, mean is highly affected by outliners thus, checking for outliners in the feature."""

# visually checking for outliners in Fuel Tank Capacity
plt.figure(figsize=(15,5))
plt.subplot(1,2,1)
sns.distplot(cars_df['Fuel Tank Capacity'])
plt.title('Density Distribution of Fuel Tank Capacity')

plt.subplot(1,2,2)
sns.boxplot(cars_df['Fuel Tank Capacity'])
plt.title('Fuel Tank Capacity')

"""According to the above plots, the feature have a few outliners where the fuel tank capacity exceeds 80."""

# checking the records where the fuel tank capacity exceeds 80
cars_df.loc[(cars_df['Fuel Tank Capacity']>80),['Make','Model','Fuel Tank Capacity']]

"""Cross verifying the data from resources, the fuel capacity specified in the data is correct and the following records are simply minority in the data and not outliners.

Hence, considering the feature do not consist of any outliners.
"""

#mean=cars_df['Fuel Tank Capacity'].mean()
#cars_df['Fuel Tank Capacity'].fillna(cars_df['Fuel Tank Capacity'].mean(), inplace=True)

# dropping records with more than 3 null values
cars_df.dropna(axis=0, how='any', subset=None, inplace=True)

cars_df.isnull().sum()

"""Finally all the null values in the data are dealt with.

###### 3. Checking for duplicate records
"""

cars_df.duplicated().any()

"""###### No duplicate records

<hr style="border:2px solid black">

### EDA

<hr style="border:2px solid black">

#### 1. Graphical representation of data distribution of features with less than 35 unique values.

(It is difficult to graphically represent the features with unique values over 35 as the graph gets too complicated and messy)
"""

# Distribution graphs of column data
def dataDistPerColumn(cars_df, nGraphShown, nGraphPerRow):
    nunique = cars_df.nunique()
    data = cars_df[[col for col in cars_df if nunique[col] > 1 and nunique[col] < 35]] 
    nRow, nCol = data.shape
    columnNames = list(data)
    nGraphRow = (nCol + nGraphPerRow - 1) / nGraphPerRow
    plt.figure(num = None, figsize = (6 * nGraphPerRow, 8 * nGraphRow), dpi = 80)
    for i in range(min(nCol, nGraphShown)):
        plt.subplot(3, nGraphPerRow, i + 1)
        columnDf = data.iloc[:, i]
        valueCounts = columnDf.value_counts()
        sns.set(rc={'figure.figsize':(8,6)})
        ax = sns.barplot(x=data.iloc[:, i].unique(), y=data.iloc[:, i].value_counts(),data=cars_df)
        if data.iloc[:, i].nunique() < 10: 
            for p in ax.patches:
             ax.annotate('{:.1f}'.format(p.get_height()), (p.get_x()+0.55, p.get_height()+0.09), rotation=0, ha='center')

        ax.set( ylabel='Number of Cars')
        plt.xticks(rotation = 90)
        plt.title(f'{columnNames[i]} (column {i})')
    plt.tight_layout(pad = 1.0, w_pad = 1.0, h_pad = 1.0)
    plt.show()

dataDistPerColumn(cars_df,9, 3)

# wordcloud function
def plot_cloud(wordcloud):
    plt.figure(figsize=(15, 5))
    plt.imshow(wordcloud) 
    plt.axis("off")

# generating word cloud
wordcloud = WordCloud(width= 3000, 
                        height = 2000, 
                        random_state=1, 
                        background_color='black', 
                        collocations=False, 
                        stopwords = STOPWORDS).generate(cars_df["Make"].to_string())
# plotting wordcloud
plot_cloud(wordcloud)

"""#### Analysing models manufactuired per company"""

#grouping models according to their manufacturers
cars_df.groupby("Make")["Model"].describe()

# graphical representation of number of models per manufacturer
sns.set(rc={'figure.figsize':(8,6)})

details=pd.DataFrame(columns=['Make','Number of Models'])
for x in cars_df['Make'].unique():
    details=details.append({'Make': x, 'Number of Models': cars_df[(cars_df['Make']==x)]['Model'].nunique()}, ignore_index=True)
#    details=details.append(x,cars_df[(cars_df['Make']==x)]['Model'].nunique())
    
ax = sns.barplot(y= details['Make'],x=details['Number of Models'], data=details, palette="gist_earth_r")
for p in ax.patches:
    ax.annotate(int(p.get_width()),((p.get_x() + p.get_width()), p.get_y()), xytext=(10, -8),fontsize=9,textcoords='offset points', ha="center")
ax.set(xlabel='\nNumber of models', ylabel='Manufacturing Company')
ax.set_title('Number of Models manufactured per Company\n')

"""#### 2. Analysing each features with unique values over 35"""

cars_df['Location'].unique()

cars_df['Location'].value_counts()

cars_df['Engine'].unique()

cars_df['Engine'].value_counts()

cars_df['Max Power'].unique()

cars_df['Max Power'].value_counts()

cars_df['Max Torque'].unique()

cars_df['Max Torque'].value_counts()

"""Analysing Target Variable

"""

#trends per year (how many cars sold per year)
plt.figure(figsize=(15,6))
plt.plot(pd.DataFrame(cars_df.groupby(["Year"])["Model"].count()),marker="o")
plt.title("Year-Wise Trend")
plt.show()

"""KDE Plot described as Kernel Density Estimate is used for visualizing the Probability Density of a continuous variable. It depicts the probability density at different values in a continuous variable. """

ax = cars_df['Price'].plot.kde()

# Statistical analysis of data
cars_df.describe()

"""###### Although describe() function treats year as a numerical feature, it is actually a categorical feature.

<hr style="border:2px solid black">

### Outliner Detection

<hr style="border:2px solid black">
"""

# Outliner Detection of column data
def outlinerDetection(cars_df, nGraphShown, nGraphPerRow):
    nunique = cars_df.nunique()
    data = cars_df [[col for col in cars_df if type(cars_df.loc[1,col]) is not str]]
    nRow, nCol = data.shape
    columnNames = list(data)
    nGraphRow = (nCol + nGraphPerRow - 1) / nGraphPerRow
    plt.figure(num = None, figsize = (4 * nGraphPerRow, 4 * nGraphRow), dpi = 80, facecolor = 'w', edgecolor = 'k')
    for i in range(min(nCol, nGraphShown)):
        plt.subplot(3, nGraphPerRow, i + 1)
        sns.boxplot(data.iloc[:, i],color="Purple")
        plt.title(f'{columnNames[i]} (column {i})')
    plt.tight_layout(pad = 1.0, w_pad = 1.0, h_pad = 1.0)
    plt.show()

outlinerDetection(cars_df,20,5)

"""###### Displaying the records that are represented as outliners by box plots"""

cars_df[(cars_df['Price']>0.5*1e7) | (cars_df['Year']<2007) | (cars_df['Kilometer']>0.2*1e6) | (cars_df['Width']>2010) | (cars_df['Width']<1450) | (cars_df['Height']>1900 | (cars_df['Height']<1200))]

"""After cross verifying the above records, it turns out that they are not outliners.

<hr style="border:2px solid black">

### Data Transformation

<hr style="border:2px solid black">
"""

# extract the numerical values using str.extract()
cars_df["Engine"] = (cars_df["Engine"].str.extract(r'(\d+)')).astype(int)
# extract the numerical values using str.extract()
cars_df["Max Power"] = (cars_df["Max Power"].str.extract(r'(\d+)')).astype(int)
# extract the numerical values using str.extract()
cars_df["Max Torque"] = (cars_df["Max Torque"].str.extract(r'(\d+)')).astype(int)

# calculating age of the cars
cars_df["Age"]=cars_df["Year"].apply(lambda x: 2023-x)

cars_df.head(2)

"""<hr style="border:2px solid black">

### Feature Selection

<hr style="border:2px solid black">
"""

# Visualize the correlations in numerical features
sns.pairplot(cars_df, hue='Price', height=2.5);

"""## Analysing the variation in features based on Target Variable"""

# Distribution graphs of column data
def plotPerColumnDistribution2(cars_df, nGraphShown, nGraphPerRow):
    nunique = cars_df.nunique()
    data = cars_df[[col for col in cars_df.columns if type(cars_df.loc[1,col]) is str and nunique[col] < 80]] # For displaying purposes, pick columns that have between 1 and 50 unique values
    nRow, nCol = data.shape
    columnNames = list(data)
    nGraphRow = (nCol + nGraphPerRow - 1) / nGraphPerRow
    plt.figure(num = None, figsize = (6 * nGraphPerRow, 8 * nGraphRow), dpi = 80, facecolor = 'w', edgecolor = 'k')
    for i in range(min(nCol, nGraphShown)):
        plt.subplot(3, nGraphPerRow, i + 1)
        columnDf = data.iloc[:, i]
        valueCounts = columnDf.value_counts()
        sns.set(rc={'figure.figsize':(8,6)})
        ax = sns.scatterplot(x=data.iloc[:, i], y=cars_df['Price'],data=cars_df)
        plt.xticks(rotation = 90)
        plt.title(f'{columnNames[i]} (column {i})')
    plt.tight_layout(pad = 1.0, w_pad = 1.0, h_pad = 1.0)
    plt.show()

plotPerColumnDistribution2(cars_df,8, 3)

# dropping feature year
cars_df.drop(["Year"], axis = 1, inplace = True)

# dropping model name
cars_df.drop(["Model"], axis = 1, inplace = True)

# dropping location feature
cars_df.drop(["Location"], axis = 1, inplace = True)

# dropping feature color
cars_df.drop(["Color"], axis = 1, inplace = True)

# dropping feature make
cars_df.drop(["Make"], axis = 1, inplace = True)

#cars_df[{'Fuel Type','Price'}].plot.bar()
plt.scatter(y=cars_df['Owner'], x = cars_df['Price'])

# mannual encoding
cars_df.replace({'Transmission':{'manual':0,'automatic':1}}, inplace=True)

# label encoding
cars_df['Seller Type'] = LabelEncoder().fit_transform(cars_df['Seller Type'])

# label encoding
cars_df['Drivetrain'] = LabelEncoder().fit_transform(cars_df['Drivetrain'])

# one hot encoding using get_dummies function
cars_df=pd.get_dummies(cars_df,columns=['Fuel Type','Owner'],drop_first=True)

# transformed data
cars_df.info()

"""<hr>

### Train-Test Split
"""

# splitting the data as 80% training and 20% test
X = cars_df.drop(['Price'],axis=1)
y = cars_df['Price']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

"""<hr>

Dropping Features using Pearson Correlation
"""

# calculating correlation between each feature
cor_mat=X_train.corr()

plt.figure(figsize=(20,20))
ax = sns.heatmap(
    cor_mat, 
    vmin=-1, vmax=1, center=0,
    cmap='Blues',
    square=True,
    annot=True
)
ax.set_xticklabels(
    ax.get_xticklabels(),
    rotation=45,
    horizontalalignment='right'
);

# selecting highly correlated columns and remove the first feature that is highly correlated with any othre feature

def corr_check(data,thresh):
  col_cor = set()
  cor_matrix=cars_df.corr()
  for i in range(len(cor_matrix.columns)):
      for j in range(i):
          if abs(cor_matrix.iloc[i,j]) > thresh:
              colname = cor_matrix.columns[i]
              col_cor.add(colname)
  return col_cor

corr_features=corr_check(X_train,0.85)

corr_features

X_train=X_train.drop(corr_features,axis=1)
X_test=X_test.drop(corr_features,axis=1)

# shape of train and test data after dropping feature based on correlation
print('Shape of X train: ',X_train.shape)
print('Shape of X test: ',X_test.shape)

"""<hr>

Random forest Regressor for feature selection
"""

rf = RandomForestRegressor(random_state=0)
rf.fit(X_train,y_train)

f_i = list(zip(X_train.columns,rf.feature_importances_))
f_i.sort(key = lambda x : x[1])
plt.barh([x[0] for x in f_i],[x[1] for x in f_i])

plt.show()

importance=rf.feature_importances_
# sort the features by importance
indices = importance.argsort()

# select the bottom 10 features
bottom_features = X_train.columns[indices][:10]

# display the top features
print("Bottom 10 features:")
print(bottom_features)

# dropping unimportant features
X_train=X_train.drop(bottom_features,axis=1)
X_test=X_test.drop(bottom_features,axis=1)

# shape of train and test data after dropping feature based on feature importance
print('Shape of X train: ',X_train.shape)
print('Shape of X test: ',X_test.shape)

"""<hr style="border:2px solid black">

Selecting features based on information gain.
"""

# determine mutual information
mutual_info = mutual_info_regression(X_train, y_train)

mutual_info = pd.Series(mutual_info)
mutual_info.index=X_train.columns
mutual_info.sort_values(ascending=False)

mutual_info.sort_values(ascending=False).plot.bar()

unimp_features = set()
for feature in (mutual_info.index):
  #print(feature)
  #print(feature,mutual_info[feature])
  #type(mutual_info[feature])
  if mutual_info[feature] < 0.2:
    unimp_features.add(feature)
    #imp_features = mutual_info[feature]
#imp_features

unimp_features

"""<hr>

### Model Building

<hr style="border:2px solid black">
"""

# initialize K-Fold cross-validation 
kf = KFold(n_splits=10, shuffle=True, random_state=0)

"""1. Linear Regression"""

# initialize Linear Regression model
lreg = LinearRegression()

# perform cross-validation on the training set
lreg_cv_scores = cross_val_score(lreg, X_train, y_train, cv=kf, scoring='r2')

# plot bar graph for R2 score for each itteration
plt.bar(range(1, len(lreg_cv_scores)+1), lreg_cv_scores)
plt.xlabel('Fold')
plt.ylabel('R2 Score')
plt.title('R2 Score for Each Fold for Linear Regression')
plt.show()

# fit the model on the training set
lreg.fit(X_train, y_train)

# predict on the test set
lreg_y_pred = lreg.predict(X_test)

# model evaluation
lreg_r2 = r2_score(y_test, lreg_y_pred)
lreg_mse = mean_squared_error(y_test, lreg_y_pred)
lreg_mae = mean_absolute_error(y_test, lreg_y_pred)
print('R2 score on the test set:', lreg_r2)
print('Mean Squared Error on the test set:', lreg_mse)
print('Mean Absolute Error on the test set:', lreg_mae)

# plot actual vs predicted values on the test set
plt.scatter(y_test, lreg_y_pred, color='green')
plt.plot(y_test,y_test, color='orange')
plt.xlabel('Actual Values')
plt.ylabel('Predicted Values')
plt.title('Actual vs Predicted Values for Linear Regression')
plt.show()

# creating a data frame to store the values of R2 score for all algorithms deployed
evaluation=pd.DataFrame({'Model':[],'R2 Score':[]})

# storing the value of R2 score for Linear Regression
evaluation.loc[0]=['Linear Regression for all Records',lreg_r2]

"""<hr>

2. Random Forest Regressor
"""

# initialize Random Forest Rgressor model
rf = RandomForestRegressor(n_estimators=100, random_state=1)

# perform cross-validation on the training set
rf_cv_scores = cross_val_score(lreg, X_train, y_train, cv=kf, scoring='r2')

# plot bar graph for R2 score for each itteration
plt.bar(range(1, len(rf_cv_scores)+1), rf_cv_scores)
plt.xlabel('Fold')
plt.ylabel('R2 Score')
plt.title('R2 Score for Each Fold for Random Forest Rgressor')
plt.show()

# fit the model on the training set
rf.fit(X_train, y_train)

# predict on the test set
rf_y_pred = rf.predict(X_test)

# model evaluation
rf_r2 = r2_score(y_test, rf_y_pred)
rf_mse = mean_squared_error(y_test, rf_y_pred)
rf_mae = mean_absolute_error(y_test, rf_y_pred)
print('R2 score on the test set:', rf_r2)
print('Test set Mean Absolute Error:', rf_mse)
print('Test set Mean Absolute Error:', rf_mae)

# plot actual vs predicted values on the test set
plt.scatter(y_test, rf_y_pred , color= 'green')
plt.plot(y_test,y_test, color='orange')
plt.xlabel('Actual Values')
plt.ylabel('Predicted Values')
plt.title('Actual vs Predicted Values for Random Forest Rgressor')
plt.show()

# storing the value of R2 score for Random Forest Regressor
evaluation.loc[1]=['Random Forest',rf_r2]

"""<hr>

3. Gradient Booster
"""

# initialize Gradient Boosting Regressor model
gb = GradientBoostingRegressor()

# perform cross-validation on the training set
gb_cv_scores = cross_val_score(gb, X_train, y_train, cv=kf, scoring='r2')

# plot bar graph for R2 score for each itteration
plt.bar(range(1, len(gb_cv_scores)+1), gb_cv_scores)
plt.xlabel('Fold')
plt.ylabel('R2 Score')
plt.title('R2 Score for Each Fold for Gradient Boosting Regressor')
plt.show()

# fit the model on the training set
gb.fit(X_train, y_train)

# predict on the test set
gb_y_pred = gb.predict(X_test)

# model evaluation
gb_r2 = r2_score(y_test, gb_y_pred)
gb_mse = mean_squared_error(y_test, gb_y_pred)
gb_mae = mean_absolute_error(y_test, gb_y_pred)
print('R2 score on the test set:', gb_r2)
print('Test set Mean Squared Error:', gb_mse)
print('Test set Mean Absolute Error:', gb_mae)

# plot actual vs predicted values on the test set
plt.scatter(y_test, gb_y_pred, color= 'green')
plt.plot(y_test,y_test, color='orange')
plt.xlabel('Actual Values')
plt.ylabel('Predicted Values')
plt.title('Actual vs Predicted Values for Gradient Boosting Regressor')
plt.show()

# storing the value of R2 score for Gradient Booster
evaluation.loc[2]=['Gradient Booster',gb_r2]

"""<hr>

4. ANN
"""

# scaling the input features
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

# creating ANN model
model = Sequential()
model.add(Dense(units=32, activation='relu', input_dim=X_train.shape[1]))
model.add(Dense(units=64, activation='relu'))
model.add(Dense(units=1))

# compiling the model
model.compile(optimizer='adam', loss='mean_squared_error')

# train the model on train set
model.fit(X_train, y_train, epochs=100, batch_size=16, verbose=1)

# model evaluation
ann_y_pred = model.predict(X_test)
ann_r2 = r2_score(y_test, ann_y_pred)
ann_mse = mean_squared_error(y_test, ann_y_pred)
ann_mae = mean_absolute_error(y_test, ann_y_pred)
print('R2 score on the test set:', ann_r2)
print('Test set Mean Squared Error:', ann_mse)
print('Test set Mean Absolute Error:', ann_mae)


# plot the actual vs predicted values
plt.scatter(y_test, ann_y_pred, color= 'green')
plt.plot(y_test, y_test, color='orange')
plt.title('Actual vs Predicted for ANN')
plt.xlabel('Actual')
plt.ylabel('Predicted')
plt.show()

# storing the value of R2 score for ANN
evaluation.loc[3]=['ANN',ann_r2]

"""<hr>

Dividing data based on Price Range
"""

# creating a boxplot of feature price
fig, ax = plt.subplots()
ax.boxplot(cars_df['Price'])

# getting the whiskers
whiskers = [line.get_ydata() for line in ax.lines if line.get_linestyle()=='-']

# sorting the whiskers by y-coordinate
whiskers.sort(key=lambda x: x[0])

# displaying the whisker values
print("Lower whisker: ", whiskers[0][1])
print("Upper whisker: ", whiskers[-1][1])

# spliting the data based on price range
high_Priced=cars_df[(cars_df['Price']>= 3875000)]
low_Priced=cars_df[(cars_df['Price']< 3875000)]

print('Shape of data containing high priced cars: ',high_Priced.shape)
print('Shape of data containing low priced cars: ',low_Priced.shape)

"""<hr>

Model for low range cars
"""

# spliting features and target
X_low_Priced = low_Priced.drop(['Price'], axis=1)
y_low_Priced = low_Priced['Price']


X_low_Priced=X_low_Priced.drop(corr_features,axis=1)
X_low_Priced=X_low_Priced.drop(bottom_features,axis=1)
X_low_Priced=X_low_Priced.drop(unimp_features,axis=1)

# spliting into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X_low_Priced, y_low_Priced, test_size=0.3, random_state=0)

# initializing Linear Regression model
lr_model = LinearRegression()

# train the model on training set
lr_model.fit(X_train, y_train)

# predict car prices on test set
low_y_pred = lr_model.predict(X_test)

# model evaluation
low_r2 = r2_score(y_test, low_y_pred)
low_mse = mean_squared_error(y_test, low_y_pred)
low_mae = mean_absolute_error(y_test, low_y_pred)

print('Test set R2 Score:', low_r2)
print('Test set Mean Squared Error:', low_mse)
print('Test set Mean Absolute Error:', low_mae)

# Plot actual vs predicted values for test set
plt.scatter(y_test, low_y_pred, color= 'green')
plt.plot(y_test, y_test, color='orange')
plt.xlabel('Actual Price')
plt.ylabel('Predicted Price')
plt.title('Linear Regression for Low Range Prices')
plt.show()

"""Model for high ranged cars"""

# split features and target
X_high_Priced = high_Priced.drop(['Price'], axis=1)
y_high_Priced = high_Priced['Price']

X_high_Priced=X_high_Priced.drop(corr_features,axis=1)
X_high_Priced=X_high_Priced.drop(bottom_features,axis=1)
X_high_Priced=X_high_Priced.drop(unimp_features,axis=1)

# spliting into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X_high_Priced, y_high_Priced, test_size=0.3, random_state=0)

# initialize Linear Regression model
lr_model = LinearRegression()

# train the model on training set
lr_model.fit(X_train, y_train)

# predict car prices on test set
high_y_pred = lr_model.predict(X_test)

# model evaluation
high_r2 = r2_score(y_test, high_y_pred)
high_mse = mean_squared_error(y_test, high_y_pred)
high_mae = mean_absolute_error(y_test, high_y_pred)

print('Test set R2 Score:', high_r2)
print('Test set Mean Squared Error:', high_mse)
print('Test set Mean Absolute Error:', high_mae)

# plot actual vs predicted values for test set
plt.scatter(y_test, high_y_pred, color= 'green')
plt.plot(y_test, y_test, color='orange')
plt.xlabel('Actual Price')
plt.ylabel('Predicted Price')
plt.title('Linear Regression for High Range Prices')
plt.show()

# storing the value of silhouette score for K-means
evaluation.loc[4]=['Linear Reg for Low Prices',low_r2]
evaluation.loc[5]=['Linear Reg for High Prices',high_r2]

"""<hr>

### Comparing Model Performances
"""

# Put the data into a list
data = [lreg_cv_scores, rf_cv_scores, gb_cv_scores]

# Set up the plot
fig, ax = plt.subplots()

# Add the box plots with colors
boxplot = ax.boxplot(data, patch_artist=True)

# Set the colors for each box
colors = ['yellow', 'green', 'indigo']
for patch, color in zip(boxplot['boxes'], colors):
    patch.set_facecolor(color)


# Add labels and title
ax.set_xticklabels(['Linear Regression', 'Random Forest Regressor', 'Gradient Booster Regression'])
ax.set_xlabel('Models')
ax.set_ylabel('R2 Score')
ax.set_title('Comparing Performance of Models for each Folds of Cross Validation')

# Show the plot
plt.show()

# comparing R2 Score of all models
fig = plt.figure(figsize=(20, 6))
ax = plt.axes()
sns.barplot(x=evaluation.iloc[:,0],y=evaluation.iloc[:,1],data=evaluation)
plt.xlabel("Regression Models")
plt.ylabel("R2 Scores")
plt.title("Comparing Various Regression Models Deployed")

"""<hr>

### Hyper Parameter Tuning
"""

# scale the input features using StandardScaler
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# initialize Random Forest model
rf_model = RandomForestRegressor(random_state=42)

# define hyperparameters to search over
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [None, 5, 10],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
}

# define GridSearchCV with 5-fold cross-validation
grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, n_jobs=-1)

# fit the GridSearchCV object to training set
grid_search.fit(X_train, y_train)

# displaying the best hyperparameters and corresponding R2 score on validation set
print('Best Hyperparameters:', grid_search.best_params_)
print('Best R2 Score on Validation Set:', grid_search.best_score_)

# model evaluation
best_rf_model = grid_search.best_estimator_
y_pred_test = best_rf_model.predict(X_test)
r2_test = r2_score(y_test, y_pred_test)
mse_test = mean_squared_error(y_test, y_pred_test)
print('Test set R2 Score:', r2_test)
print('Test set Mean Squared Error:', mse_test)

# plot actual vs predicted values for test set
plt.scatter(y_test, y_pred_test)
plt.plot(y_test, y_test, color='black')
plt.xlabel('Actual Price')
plt.ylabel('Predicted Price')
plt.title('Random Forest Regression - Actual vs Predicted Prices')
plt.show()